{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch pandas numpy plotly matplotlib tqdm scikit-learn missingno statsmodels xgboost lightgbm seaborn catboost pmdarima darts pytorch-forecasting pytorch-lightning dask"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "17uPc8Cqxg_X",
        "outputId": "a5b64e07-4c54-47d0-b640-af4f78e8ebbf"
      },
      "id": "17uPc8Cqxg_X",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (5.24.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.67.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: missingno in /usr/local/lib/python3.10/dist-packages (0.5.2)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.10/dist-packages (0.14.4)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (2.1.3)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.10/dist-packages (4.5.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.13.2)\n",
            "Requirement already satisfied: catboost in /usr/local/lib/python3.10/dist-packages (1.2.7)\n",
            "Requirement already satisfied: pmdarima in /usr/local/lib/python3.10/dist-packages (2.0.4)\n",
            "Requirement already satisfied: darts in /usr/local/lib/python3.10/dist-packages (0.32.0)\n",
            "Collecting pytorch-forecasting\n",
            "  Downloading pytorch_forecasting-1.2.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.10/dist-packages (2.5.0.post0)\n",
            "Requirement already satisfied: dask in /usr/local/lib/python3.10/dist-packages (2024.10.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly) (9.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from plotly) (24.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from statsmodels) (1.0.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.10/dist-packages (from xgboost) (2.23.4)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: Cython!=0.29.18,!=0.29.31,>=0.29 in /usr/local/lib/python3.10/dist-packages (from pmdarima) (3.0.11)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from pmdarima) (2.2.3)\n",
            "Requirement already satisfied: setuptools!=50.0.0,>=38.6.0 in /usr/local/lib/python3.10/dist-packages (from pmdarima) (75.1.0)\n",
            "Requirement already satisfied: holidays>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from darts) (0.63)\n",
            "Requirement already satisfied: nfoursid>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from darts) (1.0.1)\n",
            "Requirement already satisfied: pyod>=0.9.5 in /usr/local/lib/python3.10/dist-packages (from darts) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.10/dist-packages (from darts) (2.32.3)\n",
            "Requirement already satisfied: shap>=0.40.0 in /usr/local/lib/python3.10/dist-packages (from darts) (0.46.0)\n",
            "Requirement already satisfied: statsforecast>=1.4 in /usr/local/lib/python3.10/dist-packages (from darts) (2.0.0)\n",
            "Requirement already satisfied: tbats>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from darts) (1.1.3)\n",
            "Requirement already satisfied: xarray>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from darts) (2024.11.0)\n",
            "Requirement already satisfied: tensorboardX>=2.1 in /usr/local/lib/python3.10/dist-packages (from darts) (2.6.2.2)\n",
            "Collecting lightning<3.0.0,>=2.0.0 (from pytorch-forecasting)\n",
            "  Downloading lightning-2.5.0.post0-py3-none-any.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.4/40.4 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (6.0.2)\n",
            "Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (1.6.1)\n",
            "Requirement already satisfied: lightning-utilities>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (0.11.9)\n",
            "Requirement already satisfied: click>=8.1 in /usr/local/lib/python3.10/dist-packages (from dask) (8.1.7)\n",
            "Requirement already satisfied: cloudpickle>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from dask) (3.1.0)\n",
            "Requirement already satisfied: partd>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from dask) (1.4.2)\n",
            "Requirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from dask) (0.12.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.13.0 in /usr/local/lib/python3.10/dist-packages (from dask) (8.5.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (3.11.10)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=4.13.0->dask) (3.21.0)\n",
            "Requirement already satisfied: locket in /usr/local/lib/python3.10/dist-packages (from partd>=1.4.0->dask) (1.0.0)\n",
            "Requirement already satisfied: numba>=0.51 in /usr/local/lib/python3.10/dist-packages (from pyod>=0.9.5->darts) (0.60.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->darts) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->darts) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->darts) (2024.12.14)\n",
            "Requirement already satisfied: slicer==0.0.8 in /usr/local/lib/python3.10/dist-packages (from shap>=0.40.0->darts) (0.0.8)\n",
            "Requirement already satisfied: coreforecast>=0.0.12 in /usr/local/lib/python3.10/dist-packages (from statsforecast>=1.4->darts) (0.0.15)\n",
            "Requirement already satisfied: fugue>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from statsforecast>=1.4->darts) (0.9.1)\n",
            "Requirement already satisfied: utilsforecast>=0.1.4 in /usr/local/lib/python3.10/dist-packages (from statsforecast>=1.4->darts) (0.2.10)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX>=2.1->darts) (4.25.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.18.3)\n",
            "Requirement already satisfied: triad>=0.9.7 in /usr/local/lib/python3.10/dist-packages (from fugue>=0.8.1->statsforecast>=1.4->darts) (0.9.8)\n",
            "Requirement already satisfied: adagio>=0.2.4 in /usr/local/lib/python3.10/dist-packages (from fugue>=0.8.1->statsforecast>=1.4->darts) (0.2.6)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51->pyod>=0.9.5->darts) (0.43.0)\n",
            "Requirement already satisfied: pyarrow>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from triad>=0.9.7->fugue>=0.8.1->statsforecast>=1.4->darts) (17.0.0)\n",
            "Requirement already satisfied: fs in /usr/local/lib/python3.10/dist-packages (from triad>=0.9.7->fugue>=0.8.1->statsforecast>=1.4->darts) (2.4.16)\n",
            "Requirement already satisfied: appdirs~=1.4.3 in /usr/local/lib/python3.10/dist-packages (from fs->triad>=0.9.7->fugue>=0.8.1->statsforecast>=1.4->darts) (1.4.4)\n",
            "Downloading pytorch_forecasting-1.2.0-py3-none-any.whl (181 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.9/181.9 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning-2.5.0.post0-py3-none-any.whl (815 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m815.2/815.2 kB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lightning, pytorch-forecasting\n",
            "Successfully installed lightning-2.5.0.post0 pytorch-forecasting-1.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-d_O62JXjbdK",
        "outputId": "dc6c9420-cdc8-4a4f-8b68-458bbd920f03"
      },
      "id": "-d_O62JXjbdK",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "33659962-9a0b-4cac-8d19-3184163cc153",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33659962-9a0b-4cac-8d19-3184163cc153",
        "outputId": "a0fd5dc7-7b05-41d6-a6d1-ec133f004332"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ],
      "source": [
        "#Changing the working directory to the root\n",
        "%cd /content/drive/MyDrive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#%run download_data.py"
      ],
      "metadata": {
        "id": "rGjwkI4NtSX-"
      },
      "id": "rGjwkI4NtSX-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%run test_data_download.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EoHOcISXyBXv",
        "outputId": "822c571f-c3e4-4762-9a2e-ee3b8a2a801e"
      },
      "id": "EoHOcISXyBXv",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "######################### All data downloaded correctly! #########################\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%run test_installation.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "XTxTY25uxdWT",
        "outputId": "f43641ef-859f-4fd0-f302-ef5b88a572dc"
      },
      "id": "XTxTY25uxdWT",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU: True | # of GPU: 1| Default GPU Name: Tesla T4\n",
            "######################### All Libraries imported without errors! #########################\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bce03d17-9b58-44ba-8aed-eb016815bc85",
      "metadata": {
        "id": "bce03d17-9b58-44ba-8aed-eb016815bc85"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "import os\n",
        "import plotly.io as pio\n",
        "pio.templates.default = \"plotly_white\"\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from tqdm.autonotebook import tqdm\n",
        "# %load_ext autoreload\n",
        "# %autoreload 2\n",
        "np.random.seed()\n",
        "tqdm.pandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47449e71-2fb2-43f6-92cc-9bb0190c098f",
      "metadata": {
        "tags": [],
        "id": "47449e71-2fb2-43f6-92cc-9bb0190c098f"
      },
      "source": [
        "# Reading data to pandas dataframe\n",
        "\n",
        "Let's use London Smart Meters dataset from Kaggle for the current exercise. The source of the data is from London Data Store and Jean-Michel D. has augumented the dataset with a few more details and packaged it as a Kaggle Dataset.\n",
        "\n",
        "## About the Dataset\n",
        "\n",
        "London Data Store, free and open data-sharing portal, provided this dataset, which was collected and enriched by Jean-Michel D and uploaded on Kaggle @ https://www.kaggle.com/jeanmidev/smart-meters-in-london.\n",
        "The dataset has energy consumption readings for a sample of 5,567 London Households that took part in the UK Power Networks led Low Carbon London project between November 2011 and February 2014. Readings were taken at half hourly intervals. Some metadata about the households are also available as part of the dataset.\n",
        "\n",
        "## Data Wrangling\n",
        "The Kaggle dataset also has the time series data preprocessed on a daily level and combined all the separate files, etc. But let’s ignore those files and start with the raw files, which is in the hhblock_dataset folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b363d00d-7f4d-494a-8317-938e30a66590",
      "metadata": {
        "id": "b363d00d-7f4d-494a-8317-938e30a66590"
      },
      "outputs": [],
      "source": [
        "os.makedirs(\"imgs/chapter_2\", exist_ok=True)\n",
        "source_data = Path(\"data/london_smart_meters/\")\n",
        "block_data_path = source_data/\"hhblock_dataset\"/\"hhblock_dataset\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "801ed620-92a0-4539-a3c0-f23fe52d9c14",
      "metadata": {
        "id": "801ed620-92a0-4539-a3c0-f23fe52d9c14"
      },
      "outputs": [],
      "source": [
        "assert block_data_path.is_dir(), \"Please check if the dataset has been downloaded properly. Refer to the Preface of the book or the Readme in the repo for expected data\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c24a701f-df4e-4b25-b980-aebb0c57361f",
      "metadata": {
        "tags": [],
        "id": "c24a701f-df4e-4b25-b980-aebb0c57361f"
      },
      "source": [
        "### Converting the half hourly block level dataset into a time series data\n",
        "\n",
        "Let's pick one block and see how we can transform the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33d1bfe9-fd32-4f13-8c53-2a5d12e66df5",
      "metadata": {
        "id": "33d1bfe9-fd32-4f13-8c53-2a5d12e66df5"
      },
      "outputs": [],
      "source": [
        "block_1 = pd.read_csv(block_data_path/\"block_0.csv\", parse_dates=False)\n",
        "\n",
        "block_1['day'] = pd.to_datetime(block_1['day'], yearfirst=True)\n",
        "\n",
        "block_1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9bc08a06-725f-45e4-ac22-d018a7d5317b",
      "metadata": {
        "id": "9bc08a06-725f-45e4-ac22-d018a7d5317b"
      },
      "outputs": [],
      "source": [
        "#Check End Dates of all time series\n",
        "block_1.groupby(\"LCLid\")['day'].max().sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7cadd15d-1d8a-4779-b64b-db8ba612b3b2",
      "metadata": {
        "id": "7cadd15d-1d8a-4779-b64b-db8ba612b3b2"
      },
      "outputs": [],
      "source": [
        "max_date = None\n",
        "for f in tqdm(block_data_path.glob(\"*.csv\")):\n",
        "    df = pd.read_csv(f, parse_dates=False)\n",
        "    df['day'] = pd.to_datetime(df['day'], yearfirst=True)\n",
        "    if max_date is None:\n",
        "        max_date = df['day'].max()\n",
        "    else:\n",
        "        if df['day'].max()>max_date:\n",
        "            max_date = df['day'].max()\n",
        "print(f\"Max Date across all blocks: {max_date}\")\n",
        "del df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d1271f2-201e-4544-95b7-f006bab2594a",
      "metadata": {
        "id": "4d1271f2-201e-4544-95b7-f006bab2594a"
      },
      "outputs": [],
      "source": [
        "#Reshaping the dataframe into the long form with hour blocks along the rows\n",
        "block_1 = block_1.set_index(['LCLid', \"day\"]).stack().reset_index().rename(columns={\"level_2\": \"hour_block\", 0: \"energy_consumption\"})\n",
        "#Creating a numerical hourblock column\n",
        "block_1['offset'] = block_1['hour_block'].str.replace(\"hh_\", \"\").astype(int)\n",
        "\n",
        "block_1.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07a4e040-ea80-4353-939d-4fd7ff2a2880",
      "metadata": {
        "id": "07a4e040-ea80-4353-939d-4fd7ff2a2880"
      },
      "source": [
        "#### Compact Form"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f19551b7-b632-4865-90af-2abf172da3cf",
      "metadata": {
        "id": "f19551b7-b632-4865-90af-2abf172da3cf"
      },
      "outputs": [],
      "source": [
        "def preprocess_compact(x):\n",
        "    start_date = x['day'].min()\n",
        "    name = x['LCLid'].unique()[0]\n",
        "    ### Fill missing dates with NaN ###\n",
        "    # Create a date range from  min to max\n",
        "    dr = pd.date_range(start=x['day'].min(), end=max_date, freq=\"1D\")\n",
        "    # Add hh_0 to hh_47 to columns and with some unstack magic recreating date-hh_x combinations\n",
        "    dr = pd.DataFrame(columns=[f\"hh_{i}\" for i in range(48)], index=dr).unstack().reset_index()\n",
        "    # renaming the columns\n",
        "    dr.columns = [\"hour_block\", \"day\", \"_\"]\n",
        "    # left merging the dataframe to the standard dataframe\n",
        "    # now the missing values will be left as NaN\n",
        "    dr = dr.merge(x, on=['hour_block','day'], how='left')\n",
        "    # sorting the rows\n",
        "    dr.sort_values(['day',\"offset\"], inplace=True)\n",
        "    # extracting the timeseries array\n",
        "    ts = dr['energy_consumption'].values\n",
        "    len_ts = len(ts)\n",
        "    return start_date, name, ts, len_ts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57fbbf9b-6a29-4289-9ae0-2d311388a56b",
      "metadata": {
        "id": "57fbbf9b-6a29-4289-9ae0-2d311388a56b"
      },
      "outputs": [],
      "source": [
        "def load_process_block_compact(block_df, freq=\"30min\", ts_identifier=\"series_name\", value_name=\"series_value\"):\n",
        "    grps = block_df.groupby('LCLid')\n",
        "    all_series = []\n",
        "    all_start_dates = []\n",
        "    all_names = []\n",
        "    all_data = {}\n",
        "    all_len = []\n",
        "    for idx, df in tqdm(grps, leave=False):\n",
        "        start_date, name, ts, len_ts = preprocess_compact(df)\n",
        "        all_series.append(ts)\n",
        "        all_start_dates.append(start_date)\n",
        "        all_names.append(name)\n",
        "        all_len.append(len_ts)\n",
        "\n",
        "    all_data[ts_identifier] = all_names\n",
        "    all_data['start_timestamp'] = all_start_dates\n",
        "    all_data['frequency'] = freq\n",
        "    all_data[value_name] = all_series\n",
        "    all_data['series_length'] = all_len\n",
        "    return pd.DataFrame(all_data)\n",
        "\n",
        "block1_compact = load_process_block_compact(block_1, freq=\"30min\", ts_identifier=\"LCLid\", value_name=\"energy_consumption\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b768098c-cb7b-42ff-9ff2-b09589953218",
      "metadata": {
        "id": "b768098c-cb7b-42ff-9ff2-b09589953218"
      },
      "outputs": [],
      "source": [
        "block1_compact.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22221006-26c7-4c11-92d4-7fbe6d4ec89c",
      "metadata": {
        "id": "22221006-26c7-4c11-92d4-7fbe6d4ec89c"
      },
      "outputs": [],
      "source": [
        "display(block1_compact.memory_usage(deep=True))\n",
        "print(f\"Total: {block1_compact.memory_usage(deep=True).sum()/1024**2} MB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6e178ac-5e36-466a-bc4c-a068c3fe89c3",
      "metadata": {
        "id": "d6e178ac-5e36-466a-bc4c-a068c3fe89c3"
      },
      "source": [
        "#### Expanded Form"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf102637-d9c8-4869-9d58-4e1ace5de1e7",
      "metadata": {
        "id": "bf102637-d9c8-4869-9d58-4e1ace5de1e7"
      },
      "outputs": [],
      "source": [
        "def preprocess_expanded(x):\n",
        "    start_date = x['day'].min()\n",
        "    ### Fill missing dates with NaN ###\n",
        "    # Create a date range from  min to max\n",
        "    dr = pd.date_range(start=x['day'].min(), end=x['day'].max(), freq=\"1D\")\n",
        "    # Add hh_0 to hh_47 to columns and with some unstack magic recreating date-hh_x combinations\n",
        "    dr = pd.DataFrame(columns=[f\"hh_{i}\" for i in range(48)], index=dr).unstack().reset_index()\n",
        "    # renaming the columns\n",
        "    dr.columns = [\"hour_block\", \"day\", \"_\"]\n",
        "    # left merging the dataframe to the standard dataframe\n",
        "    # now the missing values will be left as NaN\n",
        "    dr = dr.merge(x, on=['hour_block','day'], how='left')\n",
        "    dr['series_length'] = len(dr)\n",
        "    return dr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1b89d9b-a6bc-413e-aef0-b33dd2a69f5b",
      "metadata": {
        "id": "c1b89d9b-a6bc-413e-aef0-b33dd2a69f5b"
      },
      "outputs": [],
      "source": [
        "def load_process_block_expanded(block_df, freq=\"30min\"):\n",
        "    grps = block_df.groupby('LCLid')\n",
        "    all_series = []\n",
        "    for idx, df in tqdm(grps, leave=False):\n",
        "        ts = preprocess_expanded(df)\n",
        "        all_series.append(ts)\n",
        "\n",
        "    block_df = pd.concat(all_series)\n",
        "    # Recreate Offset because there would be null rows now\n",
        "    block_df['offset'] = block_df['hour_block'].str.replace(\"hh_\", \"\").astype(int)\n",
        "    # Creating a datetime column with the date | Will take some time because operation is not vectorized\n",
        "    block_df['timestamp'] = block_df['day'] + block_df['offset']*30*pd.offsets.Minute()\n",
        "    block_df['frequency'] = freq\n",
        "    block_df.sort_values([\"LCLid\",\"timestamp\"], inplace=True)\n",
        "    block_df.drop(columns=[\"_\", \"hour_block\", \"offset\", \"day\"], inplace=True)\n",
        "    return block_df\n",
        "#     del all_series\n",
        "block1_expanded = load_process_block_expanded(block_1, freq=\"30min\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9a46c20-c802-4b28-a18f-0fc3bfe3fb20",
      "metadata": {
        "id": "c9a46c20-c802-4b28-a18f-0fc3bfe3fb20"
      },
      "outputs": [],
      "source": [
        "block1_expanded.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff0ea3c3-94e4-4093-b9cf-77a8bc35198e",
      "metadata": {
        "id": "ff0ea3c3-94e4-4093-b9cf-77a8bc35198e"
      },
      "outputs": [],
      "source": [
        "display(block1_expanded.memory_usage())\n",
        "print(f\"Total: {block1_expanded.memory_usage().sum()/1024**2} MB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e76246e-bdc6-4ec9-b860-27da4071edbb",
      "metadata": {
        "id": "6e76246e-bdc6-4ec9-b860-27da4071edbb"
      },
      "outputs": [],
      "source": [
        "del block1_expanded, block_1, block1_compact"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "63eaa201-7292-4f33-8ff2-d84e5b767fee",
      "metadata": {
        "tags": [],
        "id": "63eaa201-7292-4f33-8ff2-d84e5b767fee"
      },
      "source": [
        "#### Reading and combining all the block data into a single dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2c68f5b-fe77-42a4-b375-ac6ef8f23862",
      "metadata": {
        "tags": [],
        "id": "d2c68f5b-fe77-42a4-b375-ac6ef8f23862"
      },
      "outputs": [],
      "source": [
        "block_df_l = []\n",
        "for file in tqdm(sorted(list(block_data_path.glob(\"*.csv\"))), desc=\"Processing Blocks..\"):\n",
        "    block_df = pd.read_csv(file, parse_dates=False)\n",
        "    block_df['day'] = pd.to_datetime(block_df['day'], yearfirst=True)\n",
        "    # Taking only from 2012-01-01\n",
        "    block_df = block_df.loc[block_df['day']>=\"2012-01-01\"]\n",
        "    #Reshaping the dataframe into the long form with hour blocks along the rows\n",
        "    block_df = block_df.set_index(['LCLid', \"day\"]).stack().reset_index().rename(columns={\"level_2\": \"hour_block\", 0: \"energy_consumption\"})\n",
        "    #Creating a numerical hourblock column\n",
        "    block_df['offset'] = block_df['hour_block'].str.replace(\"hh_\", \"\").astype(int)\n",
        "    block_df_l.append(load_process_block_compact(block_df, freq=\"30min\", ts_identifier=\"LCLid\", value_name=\"energy_consumption\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2334663-867e-448e-82e3-8d796872b2ee",
      "metadata": {
        "tags": [],
        "id": "e2334663-867e-448e-82e3-8d796872b2ee"
      },
      "outputs": [],
      "source": [
        "hhblock_df = pd.concat(block_df_l)\n",
        "del block_df_l\n",
        "display(hhblock_df.memory_usage(deep=True))\n",
        "print(f\"Total: {hhblock_df.memory_usage(deep=True).sum()/1024**2} MB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3395b1b5-4f51-4ea4-979c-92720896e364",
      "metadata": {
        "id": "3395b1b5-4f51-4ea4-979c-92720896e364"
      },
      "outputs": [],
      "source": [
        "hhblock_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58329ca8-2d49-4ebd-a2dc-05399a4a616f",
      "metadata": {
        "tags": [],
        "id": "58329ca8-2d49-4ebd-a2dc-05399a4a616f"
      },
      "source": [
        "### Merging additional information"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04d04aba-d859-489e-81e5-dcef0caa0d96",
      "metadata": {
        "tags": [],
        "id": "04d04aba-d859-489e-81e5-dcef0caa0d96"
      },
      "source": [
        "#### Household information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f17e77aa-99c0-407e-9ab6-9a59bc56bf58",
      "metadata": {
        "id": "f17e77aa-99c0-407e-9ab6-9a59bc56bf58"
      },
      "outputs": [],
      "source": [
        "household_info = pd.read_csv(source_data/\"informations_households.csv\")\n",
        "household_info.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e047a646-7883-40d5-8423-bd469b0ab326",
      "metadata": {
        "id": "e047a646-7883-40d5-8423-bd469b0ab326"
      },
      "outputs": [],
      "source": [
        "hhblock_df = hhblock_df.merge(household_info, on='LCLid', validate=\"one_to_one\")\n",
        "hhblock_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eeaa90fb-7fb6-4a08-a631-9a6d8ef86f40",
      "metadata": {
        "tags": [],
        "id": "eeaa90fb-7fb6-4a08-a631-9a6d8ef86f40"
      },
      "source": [
        "#### Weather and Bank Holidays"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73358282-4bf3-43ae-97f8-f96f4310ccb3",
      "metadata": {
        "id": "73358282-4bf3-43ae-97f8-f96f4310ccb3"
      },
      "outputs": [],
      "source": [
        "bank_holidays = pd.read_csv(source_data/\"uk_bank_holidays.csv\", parse_dates=False)\n",
        "bank_holidays['Bank holidays'] = pd.to_datetime(bank_holidays['Bank holidays'], yearfirst=True)\n",
        "bank_holidays.set_index(\"Bank holidays\", inplace=True)\n",
        "bank_holidays.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c5d64c6-b29b-4f6e-8c89-793fe83ecc21",
      "metadata": {
        "id": "8c5d64c6-b29b-4f6e-8c89-793fe83ecc21"
      },
      "outputs": [],
      "source": [
        "#Reindex on standard date range\n",
        "bank_holidays = bank_holidays.resample(\"30min\").asfreq()\n",
        "bank_holidays = bank_holidays.groupby(bank_holidays.index.date).ffill().fillna(\"NO_HOLIDAY\")\n",
        "bank_holidays.index.name=\"datetime\"\n",
        "bank_holidays.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b27a978-802a-4068-8c0c-eb3237886241",
      "metadata": {
        "id": "7b27a978-802a-4068-8c0c-eb3237886241"
      },
      "outputs": [],
      "source": [
        "weather_hourly = pd.read_csv(source_data/\"weather_hourly_darksky.csv\", parse_dates=False)\n",
        "weather_hourly['time'] = pd.to_datetime(weather_hourly['time'], yearfirst=True)\n",
        "weather_hourly.set_index(\"time\", inplace=True)\n",
        "weather_hourly.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10258a10-ca32-4e23-b1ec-eb430cee2b7f",
      "metadata": {
        "id": "10258a10-ca32-4e23-b1ec-eb430cee2b7f"
      },
      "outputs": [],
      "source": [
        "#Resampling at 30min and forward fill\n",
        "weather_hourly = weather_hourly.resample(\"30min\").ffill()\n",
        "weather_hourly.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d034ec41-6e2b-42fd-ac0f-6532c93c436a",
      "metadata": {
        "id": "d034ec41-6e2b-42fd-ac0f-6532c93c436a"
      },
      "outputs": [],
      "source": [
        "def map_weather_holidays(row):\n",
        "    date_range = pd.date_range(row['start_timestamp'], periods=row['series_length'], freq=row['frequency'])\n",
        "    std_df = pd.DataFrame(index=date_range)\n",
        "    #Filling Na iwth NO_HOLIDAY cause rows before earliers holiday will be NaN\n",
        "    holidays = std_df.join(bank_holidays, how=\"left\").fillna(\"NO_HOLIDAY\")\n",
        "    weather = std_df.join(weather_hourly, how='left')\n",
        "    assert len(holidays)==row['series_length'], \"Length of holidays should be same as series length\"\n",
        "    assert len(weather)==row['series_length'], \"Length of weather should be same as series length\"\n",
        "    row['holidays'] = holidays['Type'].values\n",
        "    for col in weather:\n",
        "        row[col] = weather[col].values\n",
        "    return row"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c272753d-a258-4292-af01-691e538c8e6f",
      "metadata": {
        "id": "c272753d-a258-4292-af01-691e538c8e6f"
      },
      "outputs": [],
      "source": [
        "hhblock_df = hhblock_df.progress_apply(map_weather_holidays, axis=1)\n",
        "\n",
        "hhblock_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "491d9e6f-00ce-4984-979d-1d0c44416b3c",
      "metadata": {
        "tags": [],
        "id": "491d9e6f-00ce-4984-979d-1d0c44416b3c"
      },
      "outputs": [],
      "source": [
        "del block_df, weather_hourly, bank_holidays, household_info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e25a315b-3f17-4c82-801a-2c96da54ab0e",
      "metadata": {
        "id": "e25a315b-3f17-4c82-801a-2c96da54ab0e"
      },
      "outputs": [],
      "source": [
        "display(hhblock_df.memory_usage(deep=True))\n",
        "print(f\"Total: {hhblock_df.memory_usage(deep=True).sum()/1024**2} MB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1acf0dba-a6a3-44df-bde0-44641466a322",
      "metadata": {
        "id": "1acf0dba-a6a3-44df-bde0-44641466a322"
      },
      "source": [
        "### Saving the file on disk"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "080995b2-4895-4944-9f31-b5463d7935d0",
      "metadata": {
        "id": "080995b2-4895-4944-9f31-b5463d7935d0"
      },
      "source": [
        "Saving the entire dataset in a ts file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c7b67d9-3007-4eb0-9aeb-a21a3cc0161c",
      "metadata": {
        "id": "2c7b67d9-3007-4eb0-9aeb-a21a3cc0161c"
      },
      "outputs": [],
      "source": [
        "os.makedirs(\"data/london_smart_meters/preprocessed\", exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d627cbba-e116-4aa4-8be0-a72d1a5181c8",
      "metadata": {
        "id": "d627cbba-e116-4aa4-8be0-a72d1a5181c8"
      },
      "outputs": [],
      "source": [
        "#Takes a long time to finish. Comment out and execute only if needed\n",
        "# from src.utils.data_utils import write_compact_to_ts\n",
        "# write_compact_to_ts(hhblock_df,\n",
        "#        static_columns = ['LCLid', 'start_timestamp', 'frequency','series_length', 'stdorToU', 'Acorn', 'Acorn_grouped', 'file'],\n",
        "#        time_varying_columns = ['energy_consumption', 'holidays', 'visibility', 'windBearing', 'temperature', 'dewPoint',\n",
        "#                               'pressure', 'apparentTemperature', 'windSpeed', 'precipType', 'icon','humidity', 'summary'],\n",
        "#        filename=f\"data/london_smart_meters/preprocessed/london_smart_meters_merged.ts\",\n",
        "#        sep=\";\",\n",
        "#       chunk_size=1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "616395a6-8d70-44ec-aa8f-36293cdebcd1",
      "metadata": {
        "id": "616395a6-8d70-44ec-aa8f-36293cdebcd1"
      },
      "outputs": [],
      "source": [
        "# Saving the LCLid - Acorn map as a pickle to be used later\n",
        "hhblock_df[['LCLid',\"file\", \"Acorn_grouped\"]].to_pickle(f\"data/london_smart_meters/preprocessed/london_smart_meters_lclid_acorn_map.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3c637a5-99ac-421a-9562-a25ae0d71f13",
      "metadata": {
        "id": "c3c637a5-99ac-421a-9562-a25ae0d71f13"
      },
      "source": [
        "Saving blocks in 8 chunks as parquet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7f3f53c-11e4-4dcc-9449-a043419f7162",
      "metadata": {
        "id": "c7f3f53c-11e4-4dcc-9449-a043419f7162"
      },
      "outputs": [],
      "source": [
        "# Splitting the blocks into 8 chunks\n",
        "blocks = [f\"block_{i}\" for i in range(111)]\n",
        "\n",
        "n_chunks= 8\n",
        "split_blocks = [blocks[i:i + n_chunks] for i in range(0, len(blocks), n_chunks)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29a6235e-73cb-4c6e-a320-d5d77776f6e8",
      "metadata": {
        "tags": [],
        "id": "29a6235e-73cb-4c6e-a320-d5d77776f6e8"
      },
      "outputs": [],
      "source": [
        "#Writing each chunk to disk\n",
        "for blk in tqdm(split_blocks):\n",
        "    df = hhblock_df.loc[hhblock_df.file.isin(blk)]\n",
        "    blk = [int(b.replace(\"block_\",\"\")) for b in blk]\n",
        "    block_str = f\"block_{min(blk)}-{max(blk)}\"\n",
        "    df.to_parquet(f\"data/london_smart_meters/preprocessed/london_smart_meters_merged_{block_str}.parquet\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "30fe1d27e07bcd39a201a380e0896b1a8ddc5b4c0f1bff527b499634c2e361cc"
      }
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}